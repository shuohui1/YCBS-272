{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Tree_Exercise.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arbi11/YCBS-272/blob/master/Tree_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpNwy_s0DMHO",
        "colab_type": "text"
      },
      "source": [
        "# Tree-Based Methods\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gaif7H4ZDMHQ",
        "colab_type": "text"
      },
      "source": [
        "### Load file\n",
        "Commonly two libraries are used to load a csv files.\n",
        "- numpy function `np.loadtext` and `np.genfromtext ` \n",
        "- pandas function `pd.read_csv`\n",
        "\n",
        "Here we prefer using pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmUDueNGDMHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# you need to install graphviz-python from Anaconda, \n",
        "#it is not installed by default.\n",
        "# run this line in the command line: \n",
        "#conda install python-graphviz\n",
        "\n",
        "import graphviz\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Uy6m5V6Mgka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! git clone https://github.com/arbi11/YCBS-272.git\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TQykB6VMn7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! ls\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxv6XbDkMruI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd YCBS-272/\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfsISDsFMuch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! ls\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "GE-aybEuDMHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "df1 = pd.read_csv('spamdata.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xfNgZXYDMHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1.head()\n",
        "df1.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01H7eHhlDMHc",
        "colab_type": "text"
      },
      "source": [
        "### 1-Fitting Classification Trees\n",
        "The sklearn library has a lot of useful tools for constructing classification and regression trees:\n",
        "\n",
        "Import the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDtbi0FiDMHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e11TTsjoDMHh",
        "colab_type": "text"
      },
      "source": [
        "We'll start by using classification trees to analyze the Spam data set. In order to properly evaluate the performance of a classification tree on the data, we must estimate the test error rather than simply computing the training error. We first split the observations into a training set and a test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIoiiPdSDMHi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df1.iloc[:,:57]\n",
        "y = df1.iloc[:,-1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = \\\n",
        "        train_test_split(X, y, test_size = 0.2, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrXySVb7NAh_",
        "colab_type": "text"
      },
      "source": [
        "Code a decision tree using the scikit learn library for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjxlsmG2NAAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXUwrn_3NOoB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWmgImGPNPWx",
        "colab_type": "text"
      },
      "source": [
        "Name your tree as 'classification_tree_spam'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XozM6ZAyDMHs",
        "colab_type": "text"
      },
      "source": [
        "We now use the DecisionTreeClassifier() function to fit a classification tree in order to predict Spam. Use max_depth argument to limit the depth of the tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPQx6__CDMHt",
        "colab_type": "text"
      },
      "source": [
        " Now, one of the most attractive properties of trees is that they can be graphically displayed. Unfortunately, this is a bit of a roundabout process in sklearn. We use the export_graphviz() function to export the tree structure to a temporary .dot file, and the graphviz.Source() function to display the image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBUx6V-dDMHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "export_graphviz(classification_tree_spam, \n",
        "                out_file = \"spam_tree.dot\", \n",
        "                feature_names = X_train.columns)\n",
        "\n",
        "with open(\"spam_tree.dot\") as f:\n",
        "    dot_graph = f.read()\n",
        "graphviz.Source(dot_graph)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufN4jpQ6DMHu",
        "colab_type": "text"
      },
      "source": [
        "The most important indicator of spam emails appears to be the word Dollar.\n",
        "\n",
        "Finally, let's evaluate the tree's performance on the test data. The predict() function can be used for this purpose. We can then build a confusion matrix, which shows that we are making correct predictions for around 87.8% of the test data set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAwccJESDMHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = classification_tree_spam.predict(X_test)\n",
        "cm = pd.DataFrame(confusion_matrix(y_test, pred).T, \n",
        "                  index = ['No', 'Yes'], \n",
        "                  columns = ['No', 'Yes'])\n",
        "print(cm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbI_KNKZDMH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We can use accuracy_score function\n",
        "accuracy_score(y_test, pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM3x79fhDMH3",
        "colab_type": "text"
      },
      "source": [
        "#### Exercise\n",
        "\n",
        "Now, let's try different depth of the tree and compare in terms of accuracy on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDCTsiaMOEYq",
        "colab_type": "text"
      },
      "source": [
        "dt10 = Decision Tree depth=10\n",
        "\n",
        "dt11 = Decision Tree depth=11\n",
        "\n",
        "dt12 = Decision Tree depth=12\n",
        "\n",
        "# you may play with depth and prune the tree in different levels\n",
        "\n",
        "dt10.fit(X_train,y_train)\n",
        "\n",
        "dt11.fit(X_train,y_train)\n",
        "\n",
        "dt12.fit(X_train,y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W42rygFzOVM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ2K-Y3SDMH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "y10_pred = dt10.predict(X_test)\n",
        "y11_pred = dt11.predict(X_test)\n",
        "y12_pred = dt12.predict(X_test)\n",
        "\n",
        "accuracy_score(y_test, y10_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceWMost6DMH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_score(y_test, y11_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwehSfhHDMH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_score(y_test, y12_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Za0pI58DMH-",
        "colab_type": "text"
      },
      "source": [
        "## For adavanced Usage:\n",
        "\n",
        "Move to regression if you find this section new\n",
        "\n",
        "### \"Cross-Validation\" for Depth of the Regression Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79Cwlg1fDMH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize the accuracy_score vector\n",
        "acc = []\n",
        "depth = np.arange(1, 25)\n",
        "# Calculate accuracy score on the test set for different depths of the tree\n",
        "for i in depth:\n",
        "    # Fit the Regression Tree\n",
        "    dt = DecisionTreeClassifier(max_depth=i)\n",
        "    dt.fit(X_train,y_train)\n",
        "    # Predict on the test set\n",
        "    y_pred = dt.predict(X_test)\n",
        "    # Compute the accuracy\n",
        "    score = accuracy_score(y_test, y_pred)  \n",
        "    acc.append(score)\n",
        "# Plot results    \n",
        "plt.plot(depth, acc, '-')\n",
        "plt.xlabel('Depth of the tree')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('spam');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qr-A315DMIB",
        "colab_type": "text"
      },
      "source": [
        "### Bagging Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVlLInevDMIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X = df1.iloc[:,:57]\n",
        "#y = df1.iloc[:,-1]\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1)\n",
        "\n",
        "classification_tree_spam = DecisionTreeClassifier(max_depth = 10)\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "bag = BaggingClassifier(classification_tree_spam, n_estimators=100, \\\n",
        "                        random_state=1)\n",
        "bag.fit(X_train, y_train)\n",
        "\n",
        "y_hat = bag.predict(X_train)\n",
        "accuracy_score(y_train, y_hat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgzzmlG4DMIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat = bag.predict(X_test)\n",
        "accuracy_score(y_test, y_hat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkSbwHTMDMII",
        "colab_type": "text"
      },
      "source": [
        "## 2-Fitting Regression Trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xgwm48rmDMIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "df2 = pd.read_csv('Auto.csv', na_values=['?'], na_filter=True)\n",
        "df2 = df2.dropna() #Removes the whole raw if 1 missing value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtE24tlKDMIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHUfEov5DMIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df2[['cylinders', 'displacement', 'horsepower', \\\n",
        "         'weight', 'acceleration']]\n",
        "y = df2['mpg']\n",
        "X_train, X_test, y_train, y_test = \\\n",
        "    train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d0zDBeSPbAe",
        "colab_type": "text"
      },
      "source": [
        "## Write code to create an object of Decision Tree for Regression\n",
        "\n",
        "Train it next on X_train, y_train\n",
        "\n",
        "Name your tree as : regr_tree_auto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0MdN3odDMIa",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at the tree:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9_MyYKLDMIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "export_graphviz(regr_tree_auto, \n",
        "                out_file = \"auto_tree.dot\", \n",
        "                feature_names = X_train.columns)\n",
        "\n",
        "with open(\"auto_tree.dot\") as f:\n",
        "    dot_graph = f.read()\n",
        "graphviz.Source(dot_graph)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhKScoIZDMIf",
        "colab_type": "text"
      },
      "source": [
        "Now let's see how it does on the test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "awxidii7PzCa",
        "colab": {}
      },
      "source": [
        "pred = regr_tree_auto.predict(X_test)\n",
        "\n",
        "plt.scatter(pred, \n",
        "            y_test, \n",
        "            label = 'mpg')\n",
        "\n",
        "plt.plot([0, 1], \n",
        "         [0, 1], \n",
        "         '--k', \n",
        "         transform = plt.gca().transAxes)\n",
        "\n",
        "plt.xlabel('pred')\n",
        "plt.ylabel('y_test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L50CILSNDMIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_squared_error(y_test, pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uic1jeWhDMIk",
        "colab_type": "text"
      },
      "source": [
        "#### Exercise\n",
        "\n",
        "Now, let's try different depth of the tree and compare in terms of accuracy on the test set.\n",
        "\n",
        "Define Regression trees for varying length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CHQCg6-DMIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# you may play with depth\n",
        "dt10.fit(X_train,y_train)\n",
        "dt11.fit(X_train,y_train)\n",
        "dt12.fit(X_train,y_train)\n",
        "\n",
        "y10_pred = dt10.predict(X_test)\n",
        "y11_pred = dt11.predict(X_test)\n",
        "y12_pred = dt12.predict(X_test)\n",
        "\n",
        "mean_squared_error(y_test, y10_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrfMah1wDMIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_squared_error(y_test, y11_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7lNK_2nDMIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_squared_error(y_test, y12_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ej4cHqxxDMIr",
        "colab_type": "text"
      },
      "source": [
        "### \"Cross-Validation\" for Depth of the Regression Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8Rq60rQDMIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X = df2[['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration']]\n",
        "#y = df2['mpg']\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "# Initialize the MSE vector\n",
        "mse = []\n",
        "depth = np.arange(1, 11)\n",
        "\n",
        "# Calculate MSE on the test set for different depths of the tree\n",
        "for i in depth:\n",
        "    # Fit the Regression Tree\n",
        "    dt = DecisionTreeRegressor(max_depth=i)\n",
        "    dt.fit(X_train,y_train)\n",
        "    # Predict on the test set\n",
        "    y_pred = dt.predict(X_test)\n",
        "    # Compute the MSE\n",
        "    score = mean_squared_error(y_test, y_pred)\n",
        "    \n",
        "    mse.append(score)\n",
        "    \n",
        "# Plot results    \n",
        "plt.plot(depth, mse, '-')\n",
        "plt.xlabel('Depth of the tree')\n",
        "plt.ylabel('MSE')\n",
        "plt.title('mpg');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L0Tk1YaDMIu",
        "colab_type": "text"
      },
      "source": [
        "### Advanced Usage\n",
        "### Bagging Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DF8eGLlDMIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X = df2[['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration']]\n",
        "#y = df2['mpg']\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx8aLpvZDMIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regr_tree_auto = DecisionTreeRegressor(max_depth = 2)\n",
        "\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "bag = BaggingRegressor(regr_tree_auto, n_estimators=100, random_state=1)\n",
        "bag.fit(X_train, y_train)\n",
        "\n",
        "y_hat = bag.predict(X_train)\n",
        "mean_squared_error(y_train, y_hat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X0FOf_bDMIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat = bag.predict(X_test)\n",
        "mean_squared_error(y_test, y_hat)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}